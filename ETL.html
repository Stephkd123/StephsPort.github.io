<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Elements Reference - Massively by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="#" class="logo">Data/ML Engineering project</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="generic.html">About Me</a></li>
							<!-- <li><a href="ETL.html">1:Engineer</a></li> -->
							<li><a href="sales.html">1:Analyst </a></li>
							<!-- <li><a href="flameAI.html">3:AI Engineer</a></li> -->
							<li><a href="ETL.html">2:Data/ML Engineer</a></li>
						</ul>
                        
						<ul class="icons">
							<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>
                    <div id="main">
                        <section class="post"> 
                        <h2>Project 1:</h2>
                            <header>
                                <i><h1>Analytics and  ML for Tissue suitability Classification</h1></i>
                                <h2>Domain: Healthcare Analytics </h2>
                                <p> </p>
                                <h2>Project Overview</h2>
                                <h4>Focus: Applied Machine Learning, Data Engineering, Feature Engineering </h4>
                                <h4>Tools: Python, SQL, Pandas, Scikit-learn, XGBoost, Random Forest, Logistic Regression </h4>
                            </header>
                            
                    <p>This project is a collaborative applied machine learning initiative focused on <b>classifying donor tissue suitability</b> using large, relational healthcare datasets. <br>
                        The objective was to translate complex donor, tissue, and agency-level data into <b>interpretable predictive models</b> capable of supporting data-driven decision-making in tissue suitability assessment.</p>

                            <h3>The project addressed three core analytical questions:</h3>
                            <ul>
                                <li>Which donor and tissue characteristics are most predictive of tissue suitability?</li> 
                                <li>How does agency-level behavior and performance influence suitability outcomes?</li> 
                                <li>Can machine learning models reliably classify tissue suitability using engineered clinical and operational features?</li>
                            </ul>
                            
                            <h3>Data Engineering & Preparation</h3>
                            <ul>
                            <p>I led the SQL and ETL pipeline, extracting and transforming data from multiple relational database tables to produce an analytics-ready dataset at the donorâ€“tissue grain. This involved:</p>
                            <ul>
                                <li>Designing and optimizing complex SQL joins and pivots across donor, tissue, and characterization tables.</li> 
                                <li>Ensuring data integrity while scaling to ~68,000+ records, representing the final analytical dataset.</li> 
                                <li>Standardizing temporal variables (e.g., converting mixed time units to minutes or years).</li>
                                <li>Handling missing values and outliers using domain-informed rules rather than blanket row deletion.</li> 
                                <li>Creating derived features such as donor tissue counts, agency stratifications, and ischemic time indicators.</li>
                            </ul>
                            <p><b>The result was a clean, reproducible dataset supporting both exploratory analysis and modeling.</b></p>

                            <h3>Feature Engineering & Analytical Design</h3>
                            <ul>
                            <p>Significant effort was invested in feature engineering to capture real-world behavior and trends, including:</p>
                            <ul>
                                <li>Agency-level performance metrics (e.g., suitability rates, normalized agency scores).</li> 
                                <li>Binary and categorical encodings to preserve interpretability while enabling model compatibility</li> 
                                <li>Domain-informed thresholds to retain underrepresented agencies without introducing bias</li>
                            </ul>
                            <p><b>These features enabled both predictive performance and explainability, which is critical in healthcare analytics contexts.</b></p>

                            <h3>Machine Learning Modeling</h3>
                            <ul>
                            <p>Multiple supervised learning approaches were evaluated to balance accuracy, robustness, and interpretability:</p>
                            <ul>
                                <li>Logistic Regression (baseline interpretability).</li> 
                                <li>XGBoost</li> 
                                <li>Association Rule Mining for pattern discovery</li>
                                <li>Random Forest</li> 
                            </ul>
                            <p><b>Models were trained and evaluated using cross-validation and appropriate classification metrics, with feature importance and association rules used 
                                to surface actionable insights rather than black-box predictions.<br>
                                         Data restricted due to Data compliance Agreements
                            </b></p>
                            <p>Each team member independently explored modeling strategies, promoting robustness through comparative experimentation and reducing confirmation bias.</p>
                            <header>
                                <i><h1>Comprehensive ETL process for Movie rental data Warehouse</h1></i>
                                <h2>Project Description: </h2>
                            </header>
                    <p>This project demonstrates the design and implementation of a data warehouse for a movie rental system, showcasing the entire ETL (Extract, Transform, Load) process. The goal is to understand sales trends, marketing, and operational efficiency by tracking product sales, ensuring accurate reporting, and gaining customer insights. This project highlights my proficiency in data warehousing, ETL processes, and business intelligence.</p>
                    <div class="row">

                            <h3>Key components:</h3>
                            <ol>
                            <b><li>Organizational Context and Goals</li></b>
                            <ul>
                                <li>Revenue and Sales Growth: Tracking Movie rental over time to improve top-line revenue and profitability.</li>
                                <li>Operational Efficiency: Ensuring consistent and accurate reporting across various dimensions.</li>
                                <li>Customer Insights: Understanding customer behavior and market effectiveness.</li>
                                <li>Marketing Effectiveness: Measuring the success of marketing campaigns and channels</li>
                            </ul>
                            
                            <b><li>ETL Process Overview</li></b>
                            <ul>
                                <li>Extract Phase: Data is extracted from various source systems and copied to the staging area. This includes tables such as orders, order items, agents, products, subcategories, categories, and customers.</li>
                                <li>Transform Phase: Data is cleaned, merged, and standardized. Key transformations include:</li>
                                <li>Dim_Customers: Merging internal and external customer data, standardizing marital status, and adding effective and end dates for tracking historical changes.<br />
                                    Dim_film: Updating film Language, also updated movie ratings e.g NC-17 to Adults only,and more...<br />
                                    Dim_Staff:Updating staff date format for better analysis<br />
                                    Dim_Store: Updating important Store Date format for consistency and correcting current address.</li>
                                <li>Load Phase: Transformed data is loaded into the final project database, including tables such as Dim_customers, Dim_film, Dim_store, Dim_staff, Dim_time, Dim_date.</li>
                            </ul>
                            <b><li>Physical Database Design</li></b>
                            <ul>
                                <li>Fact Table: Captures granular movie rantal data, including customer interactions, Actors, and store location.</li>
                                <li>Dimension Tables: Detailed information about films, customers, Time & Date , Actors, and store location.</li>
                                <li>Storage Estimation: Calculations for current and projected storage requirements, ensuring scalability for future growth.</li>
                            </ul>
                            <b><li>Indexing and Query Optimization</li></b>
                            <ul>
                                <li>
                                    Indexing: Creating indexes on key columns to optimize query performance.</li>
                            </ul>
                            <b><li>Metadata Management</li></b>
                            <ul>
                                <li>Source Table Metadata: Detailed descriptions of source tables and their columns.</li>
                                <li>Transform Phase Metadata: Documentation of transformations applied to data during the ETL process.</li>
                                <li>Key Business KPIs: Metrics for sales analysis, agent performance, marketing effectiveness, financial health, and scalability.</li>
                            </ul> 
                            <b> <li>Screenshots and logs</li></b>
                            <ul>
                                <li>
                                    ETL Process Execution: Screenshots of successful ETL runs, including extract, transform, and load step logs</li>
                            </ul>
                        </ol>
                                    
                         <article class="post featured">
                            <a href="#" class="image main"><img src="images/dag1.png" alt="" /></a>
                            <a href="#" class="image main"><img src="images/sakilaschema.png" alt="" /></a>
                            <ul class="actions special">
                                <li><a href="https://github.com/Stephkd123/Portfolio-Projects/blob/main/README.md" class="button large">View Git File</a></li>
                            </ul>
                        </article>
                        </div>
                    <div id="copyright">
						<ul><li>BY Stephen Keyen II</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
        </div>
	</body>
</html>
