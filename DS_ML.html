<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Elements Reference - Massively by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="#" class="logo">Data Preparation project for Knowledge Discovery </br> and ML Engineering</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="generic.html">About Me</a></li>
							<li><a href="ETL.html">1:Engineer</a></li>
                            <li><a href="sales.html">2:Analyst </a></li>
							<li><a href="flameAI.html">3:AI Engineer</a></li>
							
						</ul>
						<ul class="icons">
							<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>
                    <div id="main">
                        <section class="post">
                            <header>
                                <i><h1>Real Estate Data Cleaning & Wrangling Project</h1></i>
                                <h2>Project Description: </h2>
                            </header>
                    <p>This project demonstrates end-to-end data cleaning and preprocessing steps applied to a real estate dataset. The project highlights my ability to identify, diagnose, and handle data quality issues—including missing values, inconsistent formats, and outliers—preparing the dataset for further analysis or modeling. The process reflects practical, real-world data handling and follows current industry practices for effective data wrangling
                    <b>Project Objective: </b> To clean, standardize, and impute missing data from a real estate dataset with nearly 10,000 records, ensuring the data is accurate, complete, and usable for downstream analysis or predictive modeling. 
                    </p>
                    <div class="row">
                        <div id="main">

                            <h3>Key Steps Performed:</h3>
                            <ol> 
                                <li>Data Loading & Initial Inspection</li>
                                    <ul>
                                        <li>Loaded dataset and explored data types, missing value distributions, and column summaries.</li>
                                        <li>Identified key features with missing values and assessed their significance and impact</li>
                                    </ul>
                                <li>Missing Value Handling</li>
                                    <ul>
                                        <li>Dropped records with null values in AddressStreet, AddressCity, and AddressState due to <1% missing rate.</li>
                                        <li>Applied median imputation for Beds, Baths, and HouseArea based on distribution analysis and outlier filtering.</li>
                                        <li>Imputed "Unknown" or "Undisclosed" for categorical fields such as Lat/Long, PGAPt, Zestimate, BadgeInfo, and more</li>
                                    </ul>
                                <li>Outlier Detection & Handling</li>
                                    <ul>
                                        <li>Visualized distribution of Beds, Baths, and HouseArea to detect skewness and extreme values.</li>
                                        <li>Filtered extreme outliers and preserved the realistic range of housing attributes.</li>
                                        <li>Used logical ratios (e.g., Bath-to-Bedroom ratio) to guide accurate imputations.</li>
                                    </ul>
                                <li>Data Standardization</li>
                                    <ul>
                                        <li>Replaced inconsistent null types (NaN, None) with standardized values.</li>
                                        <li>Ensured uniform encoding across related features to support further modeling or visualization tasks.</li>
                                    </ul>
                            </ol>
                            </div>
                        
                        <header>
                            <h2>Outcome</h2>
                            <p>The dataset was transformed into a well-structured and clean format, with:</p>
                            <ul>
                                <li>Over 95% reduction in missing critical fields.</li>
                                <li>Accurate imputation based on domain logic and distribution analysis.</li>
                                <li>Clear documentation of every decision and process.</li>
                            </ul>
                        </header>
                            
                   
                            <ul class="actions special">
                                <li><a href="https://github.com/Stephkd123/Portfolio-Projects/tree/main/Data%20ETL" class="button large">View notebook on GitHub</a></li>
                            </Git File</a></li>
                            
                            </ul>

                        </div>
                    <p>--------------------------------------------------------------------------------------------------------------------------</p>

                    <header>
                        <h2>Machine Learning models</h2>
                        <p>As a data Scientist I task myself to keep learning and improving my skills set with ETL processes<br>
                        and Machine learning models. Below is the link to GitHub folder with explanatory notebooks on my expertise<br>
                        with various Machine Learning Models on practical Data-driven projects:</p>
                        <ul>
                            <li><b>Decision Tree model</b> on Titanic dataset, survival prediction.</li>
                            <li><b>Regression Tree model</b> on patient data - Heart ailment prediction.</li> 
                            <li><b>Clustering analysis using pyclustering & Kmeans</b> on business data - representing company financials, employment, equity, assets, and sales.</li>
                            <li>Models updated often...</li>
                            <ul class="actions special">
                                <li><a href="https://github.com/Stephkd123/Portfolio-Projects/tree/main/ML%20Model_NB" class="button large">View notebooks on GitHub</a></li>
                            </Git File</a></li>
                            </ul>
                        </ul>
                    </header>
                    <div id="copyright">
						<ul><li>BY Stephen Keyen II</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
        </div>
	</body>
</html>
